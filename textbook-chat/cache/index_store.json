{"docstore/data":{"120c3e1d-206a-4c93-909e-32ac81655238":{"indexId":"120c3e1d-206a-4c93-909e-32ac81655238","nodesDict":{"17343543-04e3-4dfb-a1ab-489d70cffdad":{"id_":"17343543-04e3-4dfb-a1ab-489d70cffdad","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"c2e18833-4d29-4739-95d1-03e6611b5e21","metadata":{},"hash":"NMXEzSCHfYIDKLJtYu1cHiDCZlih0Faq/Bk3W0RYrI4="},"NEXT":{"nodeId":"379d725a-6e41-4073-96bb-16c1ca5f9e7d","metadata":{},"hash":"EVL9kaSUCn+PYmZUn5BsZvxyQr1AVaX8htd3wNhkPJg="}},"hash":"cLegx1Ez/78s0RnHhHbFdaUTRs6tBoN3s00C3ZAwa98=","text":"## AI-powered and Cognition-enabled Robotics (AICOR) \n\nIn this book, we delve into the challenge of designing and implementing\ncomputer programs capable of controlling general-purpose robots. Our\nfocus is on enabling these robots to autonomously execute a wide range\nof everyday manipulation tasks, ensuring they can be dynamically and\nintuitively tasked to perform such activities. The control programs we envisage are to interpret naturally expressed\ntask requests, like \"bring me something to drink\" or \"clean up,\" and\nproficiently carry out these tasks. <figure id=\"fig:body-motion-problem\">\n<img src=\"Ch01/02-body-motion-problem.png\" />\n<figcaption>Body motion problem.</figcaption>\n</figure>\n\nIn order to do so, the control programs have to solve the **body motion\nproblem**, which is illustrated in\nFigure 1.3 and defined below:\n\n::: theo\n\nGiven:\n\n:   a naturally formulated task request\n\ninfer and execute:\n\n:   a motion of the robot body that\n\n    -   achieves the desired effects and\n\n    -   avoid unwanted side effects. :::\n\nInferring the precise body movements required to fulfill an\nunderdetermined task request represents an enormous computational\nchallenge. This task goes beyond mere execution; it involves\ninterpreting what somebody else wants one to do. It requires to\nunderstand how the physical world works and predicting the consequences\nof actions to choose action variations that will succeed. It also calls\nfor comprehensive knowledge, commonsense, and intuitive physics\nreasoning. Necessary reasoning methods include informed decision making,\nlearning from experience, prospection, action emulation, failure\nmonitoring, diagnosis, and recovery, and planning intended courses of\naction based on predicted consequences of actions. This task and how to solve it is studied and investigated in the field\nof AI-powered and cognition-enabled robotics (AICOR). AICOR represent a\ncutting-edge field where robotics are not only automated through\nartificial intelligence but also endowed with cognitive abilities\nresembling human-like understanding and decision-making. This\nintegration aims to create robots that can interact more naturally with\ntheir environment and with humans. ::: theo\nThe interdisciplinary research field dedicated to the creation and\nadvancement of such proficient robot control systems is termed\n\"AI-powered and Cognition-enabled Robotics (AICOR).","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"379d725a-6e41-4073-96bb-16c1ca5f9e7d":{"id_":"379d725a-6e41-4073-96bb-16c1ca5f9e7d","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"c2e18833-4d29-4739-95d1-03e6611b5e21","metadata":{},"hash":"NMXEzSCHfYIDKLJtYu1cHiDCZlih0Faq/Bk3W0RYrI4="},"PREVIOUS":{"nodeId":"17343543-04e3-4dfb-a1ab-489d70cffdad","metadata":{},"hash":"cLegx1Ez/78s0RnHhHbFdaUTRs6tBoN3s00C3ZAwa98="}},"hash":"EVL9kaSUCn+PYmZUn5BsZvxyQr1AVaX8htd3wNhkPJg=","text":"\" This field\nsynergizes cutting-edge and well-established methodologies from\nartificial intelligence and robotics, integrating them with principles\nand insights derived from models of human cognition. :::\n\n::: theo\nThe objective of AICOR is to understand the design and the operation of\nrobot control systems that can competently solve the body motion problem\nfor natural and dynamically changing task requests, understand what they\nare doing and how as well as the consequences of their actions and\ntranslate this understanding into successful and trustworthy action. :::\n\nAICOR robots hold immense promise in significantly enhancing the lives\nof many individuals, particularly those facing physical and cognitive\nchallenges. Some of these individuals are confined to their beds, unable\nto lead independent lives, often reliant on others for assistance, and\nat times feeling like a burden. AICOR robots have the potential to\nbridge the gap between their needs and aims and their physical\ncapabilities. By employing autonomous robots as assistive tools, these\nindividuals could obtain what they need, precisely when they need it,\nautonomously, thus eliminating the need to seek help constantly. In this\nway, robots could markedly improve their quality of life, offering a\nhigher level of independence and dignity. AICOR robots capable of interpreting naturally stated tasks and\ntranslating them into successful action are applicable across a broad\nspectrum of domains. By assuming roles in perilous situations, such as\nrescue operations, these robots can be expected to minimize risks for\nhumans. Furthermore, their integration is anticipated to yield\nsubstantial economic impact helping to sustain the workforce that is\nneeded to secure our wellbeing. By relieving human workers from\nhazardous aspects of their jobs, these robots not only safeguard health\nbut also augment productivity and quality of life. Exploring the computational models underpinning AICOR robots not only\nadvances our competence in designing and realizing robots but also\npropels progress in arguably the most profound scientific endeavor:\nunraveling the mysteries of the brain and mind, and deciphering the\nmechanisms that empower intelligent behavior.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"f9c98f55-a722-48e0-b783-cb1032a76c1e":{"id_":"f9c98f55-a722-48e0-b783-cb1032a76c1e","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"b3649374-c0eb-489a-8ed8-51df228dae92","metadata":{},"hash":"WZ4KHfHHcN1ZVXWaZ9IJeSaABsHnOqIjt1yX50gAo2A="}},"hash":"ZV+22XG7mIXbUo10Sq3cijfbzj7w+/XuY5fIw6ZDMR0=","text":"## Perspectives on robots \n\nThis section presents three key perspectives on robots:\n\n1. The first perspective characterizes robots as software-controlled\n    articulated electro-mechanical devices that accomplish their tasks\n    by moving their body. 2. The second perspective is targeted at robots that are dynamically\n    tasked with a variety of complex tasks that are to be accomplished\n    in an open environment. In this case robots are best viewed as\n    agents that have beliefs and goals and autonomously decide on the\n    corse of action in order to achieve the robustness and flexibility\n    for successful task completion\n\n3. The third perspective considers the case in which the decision\n    making has to be well informed in order to make the right choices. For example, in a chemical application the robot has to reason about\n    possible chemical reactions before pouring one substance into\n    another one. In this case it is helpful to think of the robot as an\n    information processing or cognitive system.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"1eb78506-4710-4a90-8b6c-920760085e02":{"id_":"1eb78506-4710-4a90-8b6c-920760085e02","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"e19a7401-5dca-47ae-8440-676754477220","metadata":{},"hash":"yLuJ4yLWtquJsUzcHgq5LsF93Y9axDj4/Ip8lm7a5JY="},"NEXT":{"nodeId":"25fc4447-9dcf-499f-8a0b-473e5ad96c73","metadata":{},"hash":"iltnDnGYGQGxZX/NsOh4Tit5m/Obk0xi7y5H0YqNRjg="}},"hash":"aW/4g1eklsET/rXp9Wn3/F8QEghTSS3ZCzKG1dKv0a4=","text":"### Robots as software-controlled mechanical devices \n\nLet us start with a definition of what we consider robots to be:\n\n::: theo\nA Robot is an articulated electro-mechanical device that is operated and\ncontrolled by computer programs in order to accomplish tasks. :::\n\nRobots have a physical body, which is an assembly of body parts\nincluding grippers, heads, a base, upper body, lower arms, and other\ncomponents. The body parts are connected by joints, which are actuated\nby motors. The control program orchestrates the operation of these\nmotors, enabling the robot to perform complex, coordinated movements:\nnavigating by turning the base's wheels, aligning the head towards\nspecific directions, or manipulating the arms and grippers to interact\nwith objects. This intricate coordination allows the robot to change its\nposture and exert forces on its environment, thereby accomplishing tasks\nor, in some cases, leading to unintended side effects. The crux of the\nchallenge for the robot's control program lies in interpreting a task\nrequest and devising a sequence of movements that ensures the\nachievement of the intended outcomes while at the same time mitigating\nany adverse effects. <figure id=\"img:definition robot\">\n<img src=\"Ch01/03-definition-robot.png\" />\n<figcaption>A robot agent accomplishing task requests by moving its\narticulated body as dictated by the robot control program by causing\nphysical changes in the environment.</figcaption>\n</figure>\n\nFigure 1.5 illustrates the structure of\na state-of-the-art general-purpose mobile manipulation robot,\nhighlighting several of its critical components in greater detail. The\ndiagram focusses on components that endow the robot with its principal\nmanipulation and perception capabilities. For manipulation, the robot's\nkinematic chain, which includes the shoulder, elbow, and hand joints, is\npivotal. This chain facilitates the precise movement of the robot's end\neffector, the gripper, allowing it to attain specific poses and follows\nselected trajectories. The navigation base, equipped with steerable\nwheels, provides the robot mobility, enabling it to traverse and\nposition itself within its operational surroundings. For perception,\ncrucial sensors are integrated into the robot's design. Laser sensors\nmeasure distances to obstacles in their path, providing spatial\nawareness, while cameras capture visual data from the environment.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"25fc4447-9dcf-499f-8a0b-473e5ad96c73":{"id_":"25fc4447-9dcf-499f-8a0b-473e5ad96c73","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"e19a7401-5dca-47ae-8440-676754477220","metadata":{},"hash":"yLuJ4yLWtquJsUzcHgq5LsF93Y9axDj4/Ip8lm7a5JY="},"PREVIOUS":{"nodeId":"1eb78506-4710-4a90-8b6c-920760085e02","metadata":{},"hash":"aW/4g1eklsET/rXp9Wn3/F8QEghTSS3ZCzKG1dKv0a4="}},"hash":"iltnDnGYGQGxZX/NsOh4Tit5m/Obk0xi7y5H0YqNRjg=","text":"This\nvisual input allows the robot to process and interpret task-relevant\ninformation, playing a crucial role in its interaction with the\nsurrounding world. <figure id=\"img:pr2_robot-with-components\">\n<img src=\"Ch01/04-robot-body.png\" />\n<figcaption>The mobile manipulation robot: a PR2 robot produced by\nWillow Garage.</figcaption>\n</figure>\n\nOften, the directives and information contained in a task request are\nnot sufficient to specify an appropriate sequence of detailed robot\nmovements. Consequently, the robot must perceive and interpret the\ntask's context to bridge these information gaps. To do so, the robot\nrelies on its sensors. These sensors are designed for measuring various\nphysical parameters related to both the robot's own structure and its\nexternal environment. For instance, force sensors enable the robot to\nmeasure the amount of pressure it exerts on objects, while encoders\nmeasure the extent of joint movement, even detecting if a motion is\nhindered or stalled. Additionally, other sensors are attuned to\nenvironmental attributes: contact sensors identify collisions between\nthe robot and its surroundings, distance sensors ascertain the proximity\nof nearby objects, and cameras capture visual snapshots of the robot's\nenvironment. The data acuired by these sensors provide the control\nprogram with raw information about the robot's status and its\noperational context, information that is indispensable for the\nsuccessful execution of tasks.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"758267cf-6bc6-4ec0-9060-a632b815a150":{"id_":"758267cf-6bc6-4ec0-9060-a632b815a150","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"2ab3ec04-4cd8-4086-913f-34bc9bcedca8","metadata":{},"hash":"xwKPyMoOr+G7NGuBz9/KpwjlA1ihDJ9c1sN1HjdG0jM="},"NEXT":{"nodeId":"c6afeccd-c506-429d-bc20-5cc0461c6dad","metadata":{},"hash":"Vcf9VWKjHr9+b5wCDJtCbKquwr00JWnCA9jXsTKjtdA="}},"hash":"qardbZtWPh+/Sa68ehib/ZpdZ/4gYE7K14cYAQ39z1Y=","text":"### Robots as agents \n\nAs previously discussed, robot control systems are to solve the body\nmotion problem. This challenge escalates when dealing with\ngeneral-purpose robots, where task requirements are dynamic, open-ended,\nand potentially multifaceted. General-purpose robots may be called upon\nto execute a variety of tasks, each with its own complexity and\nstructure. These tasks are often abstractly defined, lacking sufficient\ndetail, thereby necessitating the acquisition of additional information\nduring task execution to determine suitable body motions. Moreover,\nthese robots must possess robust failure detection mechanisms and\nrecovery protocols. These factors contribute to the complexity inherent\nin designing and operating general-purpose robotic systems. For example, imagine a meal preparation robot that is able to cut slices\nof bread. Since this is a very specific task, a general-purpose robot\nshould also be able to slice a cucumber, or quarter a peach. For this,\nthe robot needs to know how cutting, slicing and quartering relate to\neach other, and most importantly, how the task request can be translated\nto appropiate body motions that achieve the desired result. During task execution, a robot must continuously infer the most\nappropriate body motion, considering its current knowledge of the task,\nlearnings from ongoing actions, and assumptions about the environment. This requires bridging the gap between the limited information provided\nby the task request and the detailed, context-specific information\nnecessary for precise manipulation in varying environments. As depicted\nin Figure 1.6, this gap is bridged by the robot's\nknowledge, and its perception and reasoning capabilities.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"c6afeccd-c506-429d-bc20-5cc0461c6dad":{"id_":"c6afeccd-c506-429d-bc20-5cc0461c6dad","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"2ab3ec04-4cd8-4086-913f-34bc9bcedca8","metadata":{},"hash":"xwKPyMoOr+G7NGuBz9/KpwjlA1ihDJ9c1sN1HjdG0jM="},"PREVIOUS":{"nodeId":"758267cf-6bc6-4ec0-9060-a632b815a150","metadata":{},"hash":"qardbZtWPh+/Sa68ehib/ZpdZ/4gYE7K14cYAQ39z1Y="},"NEXT":{"nodeId":"576a0f41-7ab9-4806-9126-e191e0dbd32c","metadata":{},"hash":"+OmK1bv0Yc//2Qoe/7apgG7BKBP8JwpKA/Ot404k6Jk="}},"hash":"Vcf9VWKjHr9+b5wCDJtCbKquwr00JWnCA9jXsTKjtdA=","text":"<figure id=\"fig:need-for-reasoning\">\n<div class=\"center\">\n<div class=\"large\">\n<table>\n<tbody>\n<tr class=\"odd\">\n<td style=\"text-align: left;\"></td>\n<td style=\"text-align: right;\"><strong>context-specific body\nmotion</strong></td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">-</td>\n<td style=\"text-align: right;\"><strong>vague task request</strong></td>\n</tr>\n<tr class=\"odd\">\n<td style=\"text-align: left;\"><span class=\"math inline\"> </span></td>\n<td style=\"text-align: right;\"><span class=\"math inline\"> </span></td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">=</td>\n<td style=\"text-align: right;\"><strong>perception &amp; knowledge &amp;\nreasoning of the robot</strong></td>\n</tr>\n</tbody>\n</table>\n</div>\n</div>\n<figcaption>The gap between the information needed to generate the\ncontext-specific motions for table setting and the information contained\nin the task request has to be filled through the knowledge and the\nreasoning capabilities of the robot agent.</figcaption>\n</figure>\n\nGiven the unpredictability of tasks and environmental conditions, it is\nimpractical for robot engineers to anticipate all potential reasoning\ntasks and actions during the design phase. Instead, robot control\nsystems must be imbued with the ability to autonomously make decisions,\nshowcasing adaptability, dependability, and efficiency in diverse and\nuncertain scenarios and contexts. To promote autonomous decision-making, we conceptualize control programs\nas robot agents capable of independently executing human-scale tasks, as\nillustrated in Figure 1.7. Viewing robots as agents involves\nmodeling them as entities with cognitive capabilities, where behavior is\nguided by desires, beliefs, and intentions. These agents strive to\nfulfill task requests robustly and efficiently, aligning with the\npreferences of the individuals they serve. They formulate and maintain\nbeliefs about task-relevant contexts to make informed decisions and\nintend to act rationally, optimizing their performance based on\npredefined metrics.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"576a0f41-7ab9-4806-9126-e191e0dbd32c":{"id_":"576a0f41-7ab9-4806-9126-e191e0dbd32c","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"2ab3ec04-4cd8-4086-913f-34bc9bcedca8","metadata":{},"hash":"xwKPyMoOr+G7NGuBz9/KpwjlA1ihDJ9c1sN1HjdG0jM="},"PREVIOUS":{"nodeId":"c6afeccd-c506-429d-bc20-5cc0461c6dad","metadata":{},"hash":"Vcf9VWKjHr9+b5wCDJtCbKquwr00JWnCA9jXsTKjtdA="}},"hash":"+OmK1bv0Yc//2Qoe/7apgG7BKBP8JwpKA/Ot404k6Jk=","text":"<figure id=\"fig:top-level-agent\">\n<img src=\"Ch01/10-robot-agent-model.png\" />\n<figcaption>Top-level model of robot agents</figcaption>\n</figure>\n\nIn this conceptual framework[^1] robot agents are robots that act in an\nenvironment in order to change the state of the environment to achieve\ngoals as dictated by the task requests. The framework enables us to\ndescribe the interaction of robots and the environment they act in, how\ngoals and tasks of the robots can be stated and the goal achievement\nthrough robot actions be measured, and how robots should select their\ncourse of action in order to maximize the impact of its actions. In the rational robot framework a *robot agent* is conceptualized as an\nentity that acts in an *environment* in order to achieve its goals. The\nagent perceives the environment through its *sensors* and changes the\nstate of the environment through its physical actions. The agent is\ncontrolled through a function that maps percepts from its sensors and\nprior knowledge into an action that the robot executes. We further\nconceptualize the processes with which robots decide on their course of\naction and how the actions change the environment as an iterative\ninteraction between the robot and the environment it is operating in. In\neach iteration the robot agent\n\n1. perceives the state of the environment,\n\n2. decides on the next action, and\n\n3. executes the action in order to change its environment. The repeated execution of the steps (1. ) to (3. ) forms a so-called\n*perception-action loop*.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"456eac44-f7b6-42ed-9b90-c2f870c36d9e":{"id_":"456eac44-f7b6-42ed-9b90-c2f870c36d9e","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"096de9d8-dac5-491a-a155-8d87d445b527","metadata":{},"hash":"ZzS6I8Zsxy3oFX1B7HdqLJ5Z554HqYN5xvnKULOpofI="},"NEXT":{"nodeId":"12d5acdb-c51f-4733-8868-95489ececd85","metadata":{},"hash":"Lhx2iY78RkaNB4F4SaMjmfNn4+/Oxs9GMcVmEGCx4nU="}},"hash":"g3O2YQM5pFr6CLFHj2xqtbwHuPto7lblbp80x1Uo4/w=","text":"### Robots as information processing entities \n\nTo better understand cognitive requirements for robot control as agents,\nit is insightful to draw from human cognitive capabilities. The human\nbrain demonstrates exceptional skill in managing tasks with versatility,\nresilience, and creativity, especially evident in remote robot\noperation. Imagine a scenario: a person connects a game controller to a robot and\nuses virtual reality glasses for immersion in the robot's environment\n(refer to Figure 1.8). The person becomes the puppeteer of\nthe robot's movements, adeptly guiding it through various tasks from\nhousehold chores to intricate manual tasks. This scenario not only\nshowcases the potential of human-guided robotics but also highlights a\nkey insight: successful world interaction is essentially about\nprocessing information. <figure id=\"img:pr2_controller\">\n<img src=\"Ch01/07-game-controller.png\" style=\"width:100.0%\" />\n<figcaption>Remote control of a mobile manipulation robot with a game\ncontroller.</figcaption>\n</figure>\n\nThrough the game controller and virtual reality glasses, the person\nprocesses visual information from the robot's cameras, makes decisions,\nand translates these into commands, resulting in the robot's physical\nactions. This demonstrates the embodiment of human cognitive reasoning\nin a robot: humans leverage their cognitive skills to process\ninformation and make decisions, while the robot's actuators implement\nthese decisions in the physical world. This interaction exemplifies the\ngeneral, robust, flexible, and competent control humans have over\nrobots, achieving tasks with remarkable adaptability and problem-solving\ncapabilities evidenced through:\n\n-   Generality and Flexibility: Humans can seamlessly adapt their\n    control strategies to work with different robots, handling various\n    objects and tools. This adaptability extends to performing tasks in\n    different environments, showcasing a remarkable generalization of\n    skills. -   Competence Across Contexts: Humans can accomplish tasks in a range\n    of contexts, including situations where additional considerations,\n    such as the presence of a small child, come into play. This\n    highlights the robustness and contextual awareness inherent in human\n    control over robots. -   Handling Novelty: Humans can proficiently tackle variations of tasks\n    with novel objects and in unknown environments. This ability to\n    adapt to unforeseen circumstances underscores the flexibility and\n    problem-solving acumen of human operators.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"12d5acdb-c51f-4733-8868-95489ececd85":{"id_":"12d5acdb-c51f-4733-8868-95489ececd85","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"096de9d8-dac5-491a-a155-8d87d445b527","metadata":{},"hash":"ZzS6I8Zsxy3oFX1B7HdqLJ5Z554HqYN5xvnKULOpofI="},"PREVIOUS":{"nodeId":"456eac44-f7b6-42ed-9b90-c2f870c36d9e","metadata":{},"hash":"g3O2YQM5pFr6CLFHj2xqtbwHuPto7lblbp80x1Uo4/w="}},"hash":"Lhx2iY78RkaNB4F4SaMjmfNn4+/Oxs9GMcVmEGCx4nU=","text":"-   Learning from Various Sources: Humans can learn to accomplish novel\n    tasks through diverse sources, such as reading instructions,\n    watching instruction videos, or interacting with a teacher. This\n    learning process involves understanding the task, its nuances, and\n    potential risks. -   Understanding and Communication: Humans possess a deep understanding\n    of their actions, evident through their ability to answer questions\n    about what they are doing, why they are doing it, and how. They can\n    anticipate the consequences and risks of their intended actions and\n    consider alternative courses of action. -   Dynamic Collaboration: Humans can dynamically adapt their task\n    interpretation and preferences when jointly accomplishing a task\n    with another human. This collaborative aspect involves a shared\n    understanding and synchronized effort toward task completion. In essence, the remarkable capabilities demonstrated by humans in\ncontrolling robots highlight the synergy between information processing,\nor better cognition, and physical action. <figure id=\"img:control_system_model\">\n<img src=\"Ch01/08-robot-control-system.png\" style=\"width:92.0%\" />\n<figcaption>Control system model</figcaption>\n</figure>\n\n**In this book we investigate the question of whether we can replace the\nhuman in our setting with a computer program that can perform these\ninformation processing tasks autonomously, see\nFigure 1.9.**","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"9b7a669f-eca1-4b17-9b3e-95eb4069fd70":{"id_":"9b7a669f-eca1-4b17-9b3e-95eb4069fd70","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"ecc3a9ee-4297-4584-976f-31edd0bcff7e","metadata":{},"hash":"s6BPEk7O2Mc/JvlLPaCe0AZ7Nle/eyHWy/EWXnv9fj0="},"NEXT":{"nodeId":"7dc77078-a11e-4a0e-9641-368bca55a805","metadata":{},"hash":"ha2PkdrZyMsjR3yAqM3GAKdDEzX8lQR8IIuCgRswaww="}},"hash":"ybsnu8yDTksSXnX95+9891YQ8Vt8Qbin8FP4dRsPPG8=","text":"## Target capabilities of AICOR robot agents \n\nFigure 1.10 illustrates the cognitive capabilities of\nthe robot agents we investigate in this textbook. These include robot\nagents that can accomplish tasks in a generalized manner, for example,\ntransporting any object from any place to any destination, given they\nhave the bodily capability to do it; robot agents accomplishing complex\nmanipulation tasks requiring them to understand how the world works in\norder to act successfully in it; robot agents that learn novel task\nvariations by reading instructions and watching instruction videos,\nrequiring to recognize and understand task-critical motion patterns;\nfinally, robot agents accomplishing joint tasks with humans requiring\nthem to negotiate, infer, and satisfy shared task interpretations. The highlighted robot agents encompass a spectrum of tasks, each\ndemonstrating varying degrees of complexity and cognitive capabilities. First, we delve into the realm of a robot agent engaged in human-scale\neveryday transportation tasks, such as the nuanced activities of setting\nand cleaning a table. This example illustrates the adaptability and\ndexterity required for robots to seamlessly integrate into common\nhousehold activities. <figure id=\"img:robot-agents\">\n<img src=\"Ch01/06-evolution-robot-agents.png\" style=\"width:100.0%\" />\n<figcaption>The focus of this book are robot agents, that is robot\ncontrol programs that can be best understood by being attributed with\nbeliefs, goals, and intentions and that have a substantial degree of\nautonomy that gives them robustness, flexibility, and\ngoal-directedness.</figcaption>\n</figure>\n\nMoving to the domain of meal preparation, our exploration extends to a\nrobot agent tasked with accomplishing simple yet intricate meal\npreparation tasks. Here, the focus is on manipulating and altering the\nphysical state of objects and substances, demanding a fine-tuned\ncoordination of robotic actions and reasoning about the consequences of\nactions. Taking a leap into more advanced capabilities, the book delves into\nrobot agents that can learn novel variations of manipulation tasks by\nleveraging external sources, such as web pages like WikiHow and\ninstructional videos. This underscores the robot's ability to acquire\nnew skills and knowledge autonomously and thereby evolve it's\nunderstanding of how the world works and how to successfully act in it.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"7dc77078-a11e-4a0e-9641-368bca55a805":{"id_":"7dc77078-a11e-4a0e-9641-368bca55a805","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"ecc3a9ee-4297-4584-976f-31edd0bcff7e","metadata":{},"hash":"s6BPEk7O2Mc/JvlLPaCe0AZ7Nle/eyHWy/EWXnv9fj0="},"PREVIOUS":{"nodeId":"9b7a669f-eca1-4b17-9b3e-95eb4069fd70","metadata":{},"hash":"ybsnu8yDTksSXnX95+9891YQ8Vt8Qbin8FP4dRsPPG8="}},"hash":"ha2PkdrZyMsjR3yAqM3GAKdDEzX8lQR8IIuCgRswaww=","text":"The pinnacle of complexity within the book's scope lies in the\nexploration of robot agents capable of joint manipulation tasks\nalongside humans in human-scale everyday scenarios. This entails a\nunique set of challenges, requiring the robot agents to discern and\nfulfill human intentions rather than relying solely on pre-programmed or\nlearned instructions. The emphasis here is on collaborative and adaptive\nbehavior, showcasing the potential for robots to engage in cooperative\ntasks within real-world environments. Throughout the book, we will dissect and analyze these diverse robot\nagents, exploring the intricacies of their control systems, learning\nmechanisms, and adaptive decision- making processes.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"7ce4b423-1392-46de-8986-30e36796e839":{"id_":"7ce4b423-1392-46de-8986-30e36796e839","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"d6575da0-932d-4a63-9d84-a9f9511914f4","metadata":{},"hash":"7+x+eoRyUYLVaKgdpl/H/hu0R02ugZS134FfQ0cG7CM="},"NEXT":{"nodeId":"6a11711a-1cb0-402e-ac9d-29bfd087fddb","metadata":{},"hash":"Rdd7WZST0xyj8Oh3+EXlexci/Gi5aJvlwpkKemYSd/Y="}},"hash":"lYsg7mtFXT4QIKYvfYIvlnuoXvhd1TEnvXe//t9WdV0=","text":"## The AICOR virtual research, education, and training building \n\nThe AICOR learning environment provides a digital platform specifically\ndesigned to study, conduct research, and work in the field of AI-powered\nand cognition-enabled robotics. At the core of this platform is the\nAICOR Virtual Building (AICOR ViB), as illustrated in\nFigure 1.11. AICOR ViB, a digital hub, serves the dual\npurpose of research and education, offering virtual tours and\ninteractive experiences within the domain of AICOR. <figure id=\"img:aicor-vib\">\n<img src=\"img/Ch01/virtual-research-building.png\" style=\"width:92.0%\" />\n<figcaption>AICOR virtual research and training building.</figcaption>\n</figure>\n\nAICOR provides a comprehensive and immersive learning and research\nenvironment, which includes the following components:\n\n-   An **education floor**, which contains various learning resources:\n\n    -   the EASE learning hub\n        provides\n\n        -   a collection of [video\n            lectures](https://learning-hub.ease-crc.org/lectures) on\n            selected topics in cognition-enabled robot manipulation held\n            by leading experts in the field\n\n        -   several [virtual\n            tutorials](https://learning-hub.ease-crc.org/tutorials) on\n            software components of AICOR robots\n\n        -   [information for the resident\n            students](https://learning-hub.ease-crc.org/bremen-students)\n            at the University of Bremen. -   several virtual research laboratories facilitating\n        research-oriented education and training such as the\n\n        -   [household transportation task\n            lab](https://vib.ai.uni-bremen.de/page/labs/domestic-object-transportation-laboratory/)\n            investigating cognition-enabled robot agents accomplishing\n            transportation tasks in human environments\n\n        -   meal preparation lab investigating how to design and\n            realize generalized robot plans for categories of everyday\n            manipulation tasks, such as cutting, pouring, whisking,\n            wiping, etc. The focus is on designing plans that can\n            accomplish a task on any object or substance, with any tool,\n            for any purpose, and in any context.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"6a11711a-1cb0-402e-ac9d-29bfd087fddb":{"id_":"6a11711a-1cb0-402e-ac9d-29bfd087fddb","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"d6575da0-932d-4a63-9d84-a9f9511914f4","metadata":{},"hash":"7+x+eoRyUYLVaKgdpl/H/hu0R02ugZS134FfQ0cG7CM="},"PREVIOUS":{"nodeId":"7ce4b423-1392-46de-8986-30e36796e839","metadata":{},"hash":"lYsg7mtFXT4QIKYvfYIvlnuoXvhd1TEnvXe//t9WdV0="},"NEXT":{"nodeId":"c15259ed-4761-4691-94a8-03584e241bc9","metadata":{},"hash":"XkvI6l9VhYBnP6EVXvkT4DZRM+fCR9gP0STT/iMSwy8="}},"hash":"Rdd7WZST0xyj8Oh3+EXlexci/Gi5aJvlwpkKemYSd/Y=","text":"-   [actionable knowledge graph lab/ robot skill and competence\n            acquisition\n            lab](https://vib.ai.uni-bremen.de/page/labs/actionable-knowledge-graph-laboratory/)\n            combines web-based abstract knowledge acquisition with\n            embodied self-programming and learning to learn to acquire\n            new task variations\n\n    -   David Vernon's comprehensive resources with a\n        Wiki\n        providing a large set of excellent pointers into the field. Most\n        notable are\n\n        -   a link to David Vernon's [course on cognitive\n            robotics](http://www.vernon.eu/cognitive_robotics/index.htm)\n\n        -   a link to David Vernon's [course on artificial cognitive\n            systems](http://www.vernon.eu/ACS.htm) accompanying his\n            textbook with the same tile\n\nWithin AICOR ViB, digital twins of actual robotics research laboratories\nare available. These virtual environments provide an opportunity for\nengaging in practical exercises that are in direct correlation with the\ntextbook's material. The platform allows students to customize their\nlearning experience by selecting a robotic task, choosing a robot, and\ndefining the operational environment. This level of user interaction\nmakes AICOR ViB a functional tool for academic pursuits in AI-powered\nand cognition-enabled robotics. During a visit to a ViB laboratory, users can select a task, a robot,\nand an environment for the robot's operation. The selected components\nare integrated into a software container[^2], which can be downloaded\nand utilized on a personal computer or operated in the cloud. Access to\nthe open-source code of the robot control systems is available in these\nvirtual research laboratories. The laboratories, involving robots,\nenvironments, and tasks, are represented as knowledge bases, making them\nunderstandable and interpretable by machines. Additionally, experimental\ndata from sessions are automatically recorded and can be interactively\nanalyzed using the openEASE web-based knowledge service, enhancing the\nreproducibility of research. AICOR ViB thus provides a powerful\ninfrastructure suitable for a range of academic activities, including\nsoftware projects, thesis research, and participation in robotics\ncompetitions like RoboCup@Home.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"c15259ed-4761-4691-94a8-03584e241bc9":{"id_":"c15259ed-4761-4691-94a8-03584e241bc9","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"d6575da0-932d-4a63-9d84-a9f9511914f4","metadata":{},"hash":"7+x+eoRyUYLVaKgdpl/H/hu0R02ugZS134FfQ0cG7CM="},"PREVIOUS":{"nodeId":"6a11711a-1cb0-402e-ac9d-29bfd087fddb","metadata":{},"hash":"Rdd7WZST0xyj8Oh3+EXlexci/Gi5aJvlwpkKemYSd/Y="}},"hash":"XkvI6l9VhYBnP6EVXvkT4DZRM+fCR9gP0STT/iMSwy8=","text":"<figure id=\"img:aicor-textbook\">\n<img src=\"img/Ch01/interactive-textbook.png\" style=\"width:92.0%\" />\n<figcaption>The AICOR interactive textbook.</figcaption>\n</figure>\n\nIn conjunction with studying the book chapters, different forms of\ninteractive learning materials are accessible, as depicted in\nFigure 1.12. These resources include video lectures\nand tutorials offering detailed insights that complement the written\ncontent. Moreover, game-like environments are available where users can\nembody a robot avatar to undertake manipulation tasks. Users also have\nthe opportunity to query and interact with the knowledge bases of robots\nand robotic experiments, facilitating the visualization of answers, data\ncompilation for machine learning training sets, and the execution of\nprogramming exercises. These exercises provide a practical context to\nvalidate the efficacy of solutions, extending to complete robot control\nprograms and real robotic systems. As a student you have a digital desktop for managing all your learning\nactivities. The desktop provides access to the courses you are taking,\nthe exercises you have to complete, the literature you have collected,\nand your thesis research. The desktop is connected to learning\nmanagement system, which in our case is Moodle (Modular Object-Oriented\nDynamic Learning Environment). The learning management system serves as\na platform for educators to create and manage courses online, providing\ntools to facilitate both asynchronous and synchronous learning. Features\nof the learning environment include the ability to post and organize\ncourse content, conduct quizzes and assessments, manage enrollments, and\nfacilitate communication through forums, chats, and messaging systems.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"7301b6ea-bce2-4b3a-8c5c-d274de916fd6":{"id_":"7301b6ea-bce2-4b3a-8c5c-d274de916fd6","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"dd89d170-49d3-4d59-b1e1-1c83c84b36ef","metadata":{},"hash":"VsuwRvFrQ6Q0nfhp8TX0iBhog6CDyyTlmoAeDvIWfzw="}},"hash":"hitlUtWB16VrqleeJeOWq4olKrUdzE1NPo936EUYsgM=","text":"## Robot Agents that ... In this section we explore how robot agents accomplish different kinds\nof everyday activities that actually require a little amount of body\nmovements (often pick, carry, place motions), but in large variations\nthat require semantic domain knowledge. For each of the following exemplary tasks and the environments they are\nexecuted in, different domain knowledge needs to be accessed.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"fc881b7e-215e-477e-8ab8-fa054015ca31":{"id_":"fc881b7e-215e-477e-8ab8-fa054015ca31","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"d0802098-6ef8-4909-bbcd-caad8aa213ea","metadata":{},"hash":"TUMW7ACmPrn5Nj109c5qUFYtbiEHCSF03orZbxGXsCU="},"NEXT":{"nodeId":"94bbca29-3104-4fd2-ab28-bdbd0becb290","metadata":{},"hash":"b5NtOo8Il2QWFVYSw/si8idZTRMl4W8l3Y85LkA6QWk="}},"hash":"RrhpH9bEO+6TQ/dmDHZAXBTwWM/AqjF7oQxmoogCGI8=","text":"### ... accomplish everyday transportation tasks \n\nThe research laboratory presents a robot agent that executes tasks\nincluding setting the table, cleaning up after eating, and loading and\nunloading the dishwasher. The collection of experiments show how general\na robot control system can be programmed if it employs knowledge and\nreasoning. <figure id=\"fig:household-challenge\">\n<img src=\"Ch01/12-ease-robot-housework-challenge.png\" />\n<figcaption>The household challenge: for a robot lifetime of robot days\nperform for each meal at each day set the table, clean the table, load\nthe dishwasher, and unload it afterwards.</figcaption>\n</figure>\n\nThe control program of the robot operates based on a fundamental\nprinciple: \\\"put things where they belong.\\\" This principle breaks down\ninto a series of sophisticated pick and place actions. For instance,\nwhen setting the table for breakfast, the robot:\n\n-   Opens the drawer to fetch clean tableware. -   Picks up a cereal box, a cup, and a milk bottle from their\n    respective storage spots. -   Arranges the items neatly on the table, ensuring the setup is\n    appropriate for the meal. After the meal, the robot:\n\n-   Clears the table, carefully handling the fragile tableware. -   Loads the dishwasher with the used items, optimizing space for\n    efficiency. -   Cleans the table surface, preparing it for the next use. <figure id=\"fig:pick-up-variations\">\n<img src=\"Ch01/13-table-setting.png\" />\n<figcaption>The robot agent performing a variation of pick up actions as\npart of the household challenge: (1) opening a drawer, (2) picking\ncereal, (3) placing cup and milk, (4) carrying a tray, (5) picking a\nbowl, (6) placing milk.</figcaption>\n</figure>\n\nThe robot is equipped with an extensive knowledge base, storing detailed\ninformation about various household routines and preferences. It\nunderstands that table settings differ between breakfast, lunch, and\ndinner and adjusts its actions accordingly. The robot's adaptability is\nhighlighted by its ability to recognize and handle tableware,\nacknowledging its fragility and the possibility of stacking items\nefficiently. For instance, in a specific kitchen setup, the robot identifies the\nstorage locations of tableware, even if they vary from one kitchen to\nanother.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"94bbca29-3104-4fd2-ab28-bdbd0becb290":{"id_":"94bbca29-3104-4fd2-ab28-bdbd0becb290","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"d0802098-6ef8-4909-bbcd-caad8aa213ea","metadata":{},"hash":"TUMW7ACmPrn5Nj109c5qUFYtbiEHCSF03orZbxGXsCU="},"PREVIOUS":{"nodeId":"fc881b7e-215e-477e-8ab8-fa054015ca31","metadata":{},"hash":"RrhpH9bEO+6TQ/dmDHZAXBTwWM/AqjF7oQxmoogCGI8="}},"hash":"b5NtOo8Il2QWFVYSw/si8idZTRMl4W8l3Y85LkA6QWk=","text":"However, if placed in a new environment where the storage\nlocations are unknown, such as a different kitchen or a storage room,\nthe robot may require updates to its knowledge base to continue\nperforming efficiently. With its sophisticated task execution, adaptability, and extensive\nknowledge base, this robot represents a significant leap forward in\nhousehold automation. However, achieving such a level of functionality\nand intelligence in a robot involves overcoming substantial challenges,\nparticularly in developing a rich knowledge base and ensuring the\nrobot's adaptability to diverse household environments.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"c861d1d6-8a61-473e-a4de-7f54f5ead8ef":{"id_":"c861d1d6-8a61-473e-a4de-7f54f5ead8ef","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"686cd91f-b347-47b1-b51f-b033a19c910b","metadata":{},"hash":"bLTfE/TzcBsJwjqmAx3wjYfR13mrf+YUKIvFRl4hEbo="},"NEXT":{"nodeId":"a42223d5-79fc-46c6-ac4d-1947c056b730","metadata":{},"hash":"LvJHaN8aDYr6d0O8ZKmWc3GDXUHobAp2Q9Br1FSr038="}},"hash":"8z4IlSKbrb23bPiEbwymYx2ig/Bf9ois24AAs4BO/fU=","text":"### ... work in a retail store \n\nIn the domain of retail, robotics is beginning to revolutionize the\nshopping experience, mirroring the advancements in household robotics. The primary operations of these robots remain pick and place actions,\nbut the overarching goal shifts to \\\"looking for and ordering things.\\\"\nWhile single-task robots have made their presence felt in storage rooms\nof large logistics firms, multifunctional robots are gradually making\ntheir way to the shop floor, exemplified by shelf scanning robots used\nfor stocktaking (as visualized in\nFigure 1.15). <figure id=\"fig:store-mapping\">\n<img src=\"Ch01/14-retail-robots.png\" />\n<figcaption>Robot agent building a model of a retail store. Left: Robot\nidentifying objects in the store with its camera. Right, top: Perception\nresults of the robot. Right, bottom: Object recognition of the\nperception system.</figcaption>\n</figure>\n\nThe stocktaking robot is designed to:\n\n-   Recognize individual shelves and their respective levels. -   Detect and read the price tags of products on each shelf level. -   Count the number of products placed consecutively. Compile and\n    update all the gathered information into a database. This robot autonomously builds a model of its environment to navigate\nand perform tasks effectively. However, its capabilities are tailored to\nthe structured environment of retail stores, which are characterized by\nstandardized layouts with shelves, shelf levels, and products. The\nidentification of products is facilitated by barcodes, and the\npositioning of products facing the customers simplifies perception and\ninteraction. Despite the structured nature of retail environments, shopping or\nservice robots face numerous challenges, especially in real-time,\ncustomer-centric settings:\n\n-   Customer Traffic: Navigating through and operating in crowded\n    spaces. -   Customer Preferences: Understanding and adapting to individual\n    customer needs and behaviors. -   Fast Changing Products: Keeping up with the frequent changes in\n    product placements and new stock. -   Misplaced Products: Identifying and dealing with products that are\n    not in their designated spots. -   Narrow Spaces: Manipulating and picking products in tightly packed\n    shelves. To address these challenges, shopping robots must link the perceived\ninformation (like barcodes) to customer demands.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"a42223d5-79fc-46c6-ac4d-1947c056b730":{"id_":"a42223d5-79fc-46c6-ac4d-1947c056b730","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"686cd91f-b347-47b1-b51f-b033a19c910b","metadata":{},"hash":"bLTfE/TzcBsJwjqmAx3wjYfR13mrf+YUKIvFRl4hEbo="},"PREVIOUS":{"nodeId":"c861d1d6-8a61-473e-a4de-7f54f5ead8ef","metadata":{},"hash":"8z4IlSKbrb23bPiEbwymYx2ig/Bf9ois24AAs4BO/fU="}},"hash":"LvJHaN8aDYr6d0O8ZKmWc3GDXUHobAp2Q9Br1FSr038=","text":"For instance, if a\ncustomer is looking for the cheapest toothpaste, the robot must identify\nwhich barcodes correspond to different toothpaste brands and determine\nthe most cost-effective option. This requires integrating extensive\nproduct knowledge, potentially sourced from web stores and online\nproduct databases. Such integration enables these robots to assist\ncustomers effectively by helping them locate and identify products based\non specific criteria. Shopping assistant robots represent a significant step towards\nautomating and enhancing the retail experience. By combining\nsophisticated perception abilities, comprehensive product knowledge, and\ncustomer interaction capabilities, these robots have the potential to\ntransform the shopping landscape. However, the transition from\nstructured, predictable environments like storage rooms to dynamic,\ncustomer-driven shop floors introduces a set of challenges that\nnecessitate advanced solutions in robot design, environmental\nunderstanding, and customer service automation.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"59044102-718d-420a-ab79-f3176cf83dc4":{"id_":"59044102-718d-420a-ab79-f3176cf83dc4","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"76310068-6364-4826-99d5-1561eab40481","metadata":{},"hash":"U8NgCWry2ZZnlR9ZTu8lLlZIVPpZqg/PPOtWudJH1sQ="},"NEXT":{"nodeId":"13edd8d1-927b-451b-902c-aa0e2b7848fb","metadata":{},"hash":"bdUMORNQtGeRMA3ZB6peNpe6MKZ63Inp2wsFxtj+hms="}},"hash":"MS0Cm9C4ht/3EZagZt3G3IP+H7Krz3nfbcMS9y6YEH4=","text":"### ... prepare simple meals \n\nAnother robot you can find in the AICOR ViB is the popcorn making robot. For a visual introduction of the task, consider the snapshots of the\ncooking activity depicted in\nFigure 1.16. Additionally, a comprehensive\ndemonstration of the robot performing the complete popcorn preparation\ntask can be viewed at the provided YouTube link\n<https://www.youtube.com/watch?v=cTCJSNjTdo0>. <figure id=\"fig:making-popcorn\">\n<img src=\"Ch01/09-popcorn-making.png\" />\n<figcaption>Action steps for popcorn making: (1) putting the cooking pot\non the stove, (2) opening the drawer, (3) pouring the corn into the pot,\n(4) switching on the drawer, (5) grasping the lid, (6) putting the lid\non the pot, (7) distributing the corn evenly in pot, (8) pouring the\npopcorn onto the plate, (9) salting the popcorn.</figcaption>\n</figure>\n\nThe AICOR ViB's popcorn-making robot represents a pinnacle of robotics,\nturning a simple instruction like \\\"make popcorn\\\" into a showcase of\nadvanced robotics and AI capabilities. This task, while straightforward\nin appearance, encompasses a wealth of complex, underlying processes\nthat epitomize the intricacies of robotics in practical applications. **Analysis of Task Complexity**\n\n-   Decomposition of the High-Level Instruction: The robot must dissect\n    the command into actionable steps. It involves understanding the\n    sequence of operations, such as acquiring popcorn kernels, measuring\n    them, and setting up the cooking appliance. -   Importance of Ordering and Timing of Actions: Ensuring the correct\n    order and timing of actions is vital. The robot must comprehend the\n    sequence that leads to successful task completion, like not turning\n    on the microwave prematurely. -   Necessity of Sensorimotor Coordination: Accurate sensorimotor\n    coordination is essential. The robot navigates the kitchen, handles\n    objects (like a popcorn packet), and monitors the cooking, adapting\n    to the specific environment and tools. **Understanding and Interaction with the Environment**\n\n-   Environmental Understanding and Self-Awareness: The robot requires\n    comprehensive knowledge of the kitchen environment, including the\n    locations of items and how to operate appliances.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"13edd8d1-927b-451b-902c-aa0e2b7848fb":{"id_":"13edd8d1-927b-451b-902c-aa0e2b7848fb","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"76310068-6364-4826-99d5-1561eab40481","metadata":{},"hash":"U8NgCWry2ZZnlR9ZTu8lLlZIVPpZqg/PPOtWudJH1sQ="},"PREVIOUS":{"nodeId":"59044102-718d-420a-ab79-f3176cf83dc4","metadata":{},"hash":"MS0Cm9C4ht/3EZagZt3G3IP+H7Krz3nfbcMS9y6YEH4="}},"hash":"bdUMORNQtGeRMA3ZB6peNpe6MKZ63Inp2wsFxtj+hms=","text":"-   Procedural Knowledge and Action Sequence Dependencies: Understanding\n    the sequence of actions and their dependencies is crucial, like\n    knowing to place the pot on the stove before heating it. -   Sensory Feedback and Monitoring: The robot must monitor the process\n    through sensory feedback, like recognizing the sound of popcorn\n    popping. **Advanced System Integration**\n\n-   Environmental Mapping for Object Recognition: The robot uses\n    sophisticated mapping to recognize objects. -   Task Planning Algorithms: Algorithms are used to deduce and order\n    the steps from a high-level instruction. -   Control Systems for Precise Object Interaction: Precise interaction\n    with objects is achieved through advanced control systems. -   Sensory Processing and Learning Mechanisms: The robot adapts to new\n    environments or changes through advanced sensory processing and\n    learning mechanisms. **Physical and Interactional Considerations**\n\n-   Handling of Different Objects: The robot considers the physical\n    characteristics like weight, shape, and temperature of objects for\n    interaction. -   Task-Specific Knowledge: Knowledge of specific tasks, like where\n    popcorn is stored or how to operate a salt grinder, is crucial. **Example Task: Popcorn Making** The process involves several steps,\neach requiring context-dependent execution:\n\n1. Picking and placing an empty pot on the hotplate. 2. Turning on the hot plate. 3. Handling the corn bowl and adding corn to the pot. 4. Placing the lid on the pot. 5. Shaking the pot to prevent burning. 6. Monitoring until the popcorn is ready. 7. Turning off the hot plate. 8. Transferring the popcorn to a bowl and placing the pot in a safe\n    area.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"f626b6d2-d95e-4b96-b2b2-2319cec80a24":{"id_":"f626b6d2-d95e-4b96-b2b2-2319cec80a24","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"fbcbda37-b1c1-4f1f-9825-7a5b690cf188","metadata":{},"hash":"Iv4Q9bsMlGUuamRSe4g5KWnxl487gfDn0u6OiARcxSU="},"NEXT":{"nodeId":"872b74b8-df8b-40d3-a638-406d8bf2788c","metadata":{},"hash":"Yr4ROl6/yEZk35MZT8O2qBOsQzHAv8RI4D9v4Rr1M/A="}},"hash":"ZD0olgMRltk+LfeiL798a5at0yOkwXFTpvy6Nu0Uj0E=","text":"### ... assist in laboratories \n\nIn the realm of scientific research and testing, robots are increasingly\nbeing introduced to assist with intricate assembly tasks, such as\ncompiling chemical test kits (as shown in\nFigure 1.17). These tasks demand a nuanced\nunderstanding of physics and material properties, far beyond the\nrequirements of typical household or retail assistance robots. Laboratory assembly robots must manipulate delicate and often minuscule\ncomponents, necessitating a sophisticated blend of compositional\nknowledge, material awareness, and functional understanding. <figure id=\"fig:medical_lab\">\n<img src=\"Ch01/15-medical_lab.png\" />\n<figcaption>Robot agent assembling sterility test kits in a medical\nlaboratory. The transparent arm simulates the planned body movement of\nthe robot in order to calculate success.</figcaption>\n</figure>\n\nTo manage the intricate assembly tasks typically found in a laboratory,\na robot must possess:\n\n-   Compositional Knowledge: Understanding the assembly process, akin to\n    how humans interpret instruction sheets. -   Material Knowledge: Recognizing the properties of various materials,\n    such as the fragility of glass or the malleability of rubber, and\n    adapting manipulation strategies accordingly. -   Functional Understanding: Identifying the purpose and proper\n    application of each component within the assembly, ensuring that\n    each part is used correctly, like placing a rubber plug on the top\n    of a glass tube, not at the bottom or side. Laboratory environments offer certain advantages that facilitate the\nsuccessful deployment of robots:\n\n-   Structured Environments: Labs are meticulously organized, with each\n    tool and component having a specific place and purpose. -   Minimal Human Traffic: Unlike retail or household settings, labs\n    typically have fewer people moving around, reducing the complexity\n    of navigation and operation. -   Limited Object Variability: The number of different objects and\n    materials a robot must recognize and handle is relatively small,\n    allowing for more focused and specialized knowledge bases. -   Detailed Action Sets: The tasks are well-defined with specific steps\n    and sequences, enabling robots to follow precise instructions\n    without requiring significant on-the-fly decision-making. -   Consistency in Tasks: There's minimal variation in the tasks\n    performed, allowing robots to perfect specific routines without\n    needing to adapt to new or unexpected scenarios frequently.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"872b74b8-df8b-40d3-a638-406d8bf2788c":{"id_":"872b74b8-df8b-40d3-a638-406d8bf2788c","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"fbcbda37-b1c1-4f1f-9825-7a5b690cf188","metadata":{},"hash":"Iv4Q9bsMlGUuamRSe4g5KWnxl487gfDn0u6OiARcxSU="},"PREVIOUS":{"nodeId":"f626b6d2-d95e-4b96-b2b2-2319cec80a24","metadata":{},"hash":"ZD0olgMRltk+LfeiL798a5at0yOkwXFTpvy6Nu0Uj0E="}},"hash":"Yr4ROl6/yEZk35MZT8O2qBOsQzHAv8RI4D9v4Rr1M/A=","text":"Laboratory assembly assistant robots exemplify the integration of\nadvanced robotics in high-precision, high-stakes environments. These\nrobots, equipped with detailed knowledge of materials, physics, and\nfunctional applications, are capable of handling delicate and complex\ntasks with precision and consistency. The structured nature of\nlaboratory environments further contributes to their success, providing\na controlled setting that maximizes the robots' efficiency and accuracy. While these robots currently operate within a relatively narrow scope of\ntasks, their potential to revolutionize laboratory work by enhancing\nprecision, reducing manual errors, and increasing efficiency is\nprofound.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"81e0a02e-6fd8-4efe-b5d6-d12c59eeb56f":{"id_":"81e0a02e-6fd8-4efe-b5d6-d12c59eeb56f","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"729039b1-fba1-4268-99ba-dd36a0aeeba0","metadata":{},"hash":"kGfx2/8G/KxDRXKIg6LI82AEhjkD0nYUiSPt358mSnU="},"NEXT":{"nodeId":"5578c265-baff-4637-95a2-a79f2975a7c5","metadata":{},"hash":"I9Fa9ghf6MgUiUu6u9SQIlnBMMZO8jFJjzWp/ezRzkk="}},"hash":"/Dylj/UJadzDjcoY1VABt4c+XB5Z93Qxc64XRtbIUl8=","text":"### ... are ocean scientists \n\nTransitioning from the structured confines of human-made environments to\nthe vast and unpredictable realm of nature, underwater robots designed\nfor scientific research represent a pinnacle in robotics engineering. These robots are deployed in dynamic and often harsh natural\nenvironments to observe and analyze ecosystems over extended periods. Their tasks and operational challenges are fundamentally different from\nthose encountered in controlled settings, demanding a unique set of\ncapabilities and design considerations. <figure id=\"fig:underwater_env\">\n<img src=\"Ch01/16-remaro-robot.png\" />\n<figcaption>Underwater env 1</figcaption>\n</figure>\n\nUnderwater research robots must be equipped to handle the complexities\nof natural settings, which include:\n\n-   Advanced Sensory Capabilities: Possessing sensors that can navigate\n    and gather data in conditions with low light and high reflection,\n    typical of underwater environments. -   Autonomous Functioning: Operating independently for prolonged\n    periods without the need for external control, often in areas where\n    human intervention is not feasible. -   Self-Repair Mechanisms: Having the ability to perform diagnostics\n    and basic repairs autonomously to ensure continued operation and\n    return to the surface if necessary. -   Accurate Position Estimation: Maintaining precise navigation and\n    positional awareness even in adverse conditions, where conventional\n    systems like GPS are not operable. -   Adaptive Behavior Modeling: Understanding and predicting the\n    behavior of living organisms in their natural habitat, accounting\n    for both short-term actions and long-term patterns like breeding\n    seasons or coral growth. Building robots capable of conducting research in natural underwater\nenvironments poses significant challenges:\n\n-   Environmental Robustness: Designing systems that can withstand\n    pressure, temperature, and salinity variations, along with physical\n    obstacles and unpredictable elements. -   Energy Efficiency: Ensuring the robot can manage its energy\n    resources efficiently, especially crucial when operating\n    autonomously over extended periods. -   Data Processing and Transmission: Handling the collection,\n    processing, and, where possible, transmission of vast amounts of\n    data, often with limited bandwidth or in delayed transmission\n    scenarios. -   Interaction with Living Organisms: Developing non-intrusive methods\n    to observe and interact with marine life, ensuring that the robot's\n    presence does not adversely affect the natural behavior and balance\n    of the ecosystem.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"5578c265-baff-4637-95a2-a79f2975a7c5":{"id_":"5578c265-baff-4637-95a2-a79f2975a7c5","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"729039b1-fba1-4268-99ba-dd36a0aeeba0","metadata":{},"hash":"kGfx2/8G/KxDRXKIg6LI82AEhjkD0nYUiSPt358mSnU="},"PREVIOUS":{"nodeId":"81e0a02e-6fd8-4efe-b5d6-d12c59eeb56f","metadata":{},"hash":"/Dylj/UJadzDjcoY1VABt4c+XB5Z93Qxc64XRtbIUl8="}},"hash":"I9Fa9ghf6MgUiUu6u9SQIlnBMMZO8jFJjzWp/ezRzkk=","text":"Underwater research robots in natural environments represent an advanced\nfrontier in robotics, where the machines are not just tools but also\nexplorers and observers of the unknown. These robots hold the promise of\nunlocking mysteries of the underwater world, providing insights into\ncomplex ecological patterns and the effects of environmental changes. The design and operational challenges they face push the boundaries of\ncurrent technology, driving innovation in robotics, materials science,\nand environmental science.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"8bbb0d25-5552-4777-b467-2500ab9dc014":{"id_":"8bbb0d25-5552-4777-b467-2500ab9dc014","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"43ee3fad-3ba3-40ad-a089-77149c8592ac","metadata":{},"hash":"3rURA3NAjBbPHuOfsFmQc4zwl06mxpSGjEZOUnQ7JUU="},"NEXT":{"nodeId":"cfd8ad4a-7e5c-4e0f-a3c6-18f7aa466436","metadata":{},"hash":"8QmwwRwuOIAjwLC+V2jXjOc3NUVXNMgVPYXrGI8H7M4="}},"hash":"pwkzVOzbPYIxSKP/lKJ1Kz38HpONQaxwEp2qMK0zEGA=","text":"### ... learn to prepare meals \n\nElevating the capabilities of household robots and robots that prepare\nsimple meals, the cooking assistant robot represents a significant leap\nin domestic robotics. Unlike the relatively structured tasks of setting\nand cleaning the table, cooking introduces open-ended task categories\nwith a high degree of variability and complexity. This robot is to\nprepare meals, handling a wide range of ingredients, kitchen tools, and\ncooking techniques. <figure id=\"fig:learning-from-videos\">\n<img src=\"Ch01/17-robohow-cooking.png\" />\n<figcaption>Robot agent learning to prepare meals by watching\ninstruction videos.</figcaption>\n</figure>\n\nThe cooking robot is required to perform sophisticated cooking actions,\nsuch as:\n\n-   Cutting and Peeling: Precisely handling a variety of textures and\n    shapes of fruits, vegetables, and other ingredients. -   Mixing and Stirring: Understanding the required consistency and\n    applying the appropriate technique for different dishes. -   Differentiating Pouring Techniques: Recognizing when to pour\n    ingredients into a container versus pouring through a strainer or\n    sieve. -   Manipulating Complex Objects: Opening jars, milk cartons, cereal\n    packs, and other packaged food items with varying levels of\n    difficulty. Cooking involves not only the mechanical execution of tasks but also a\ndeep understanding of the process and sequence of actions. Instructions\nthat are intuitive to humans often lack the explicit detail required for\nrobotic comprehension. For example:\n\n-   Understanding Implicit Instructions: Instructions like \\\"Add the\n    milk to the dough, mix it, and pour it into a pan\\\" are inherently\n    understood by humans but require explicit contextual understanding\n    and sequencing for a robot. -   Differentiate between Task Requests: A general-purpose robot needs\n    to be able to relate instructions like cutting, slicing and\n    quartering and differentiate them in the ways they influence body\n    motions. -   Learning from Demonstrations: An effective approach for teaching\n    cooking to robots involves learning from demonstrations, where\n    robots observe and interpret human actions. This method allows\n    robots to perceive executed actions and understand the nuances of\n    task variations by comparing different demonstrations (as\n    illustrated in\n    Figure 1.19).","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"cfd8ad4a-7e5c-4e0f-a3c6-18f7aa466436":{"id_":"cfd8ad4a-7e5c-4e0f-a3c6-18f7aa466436","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"43ee3fad-3ba3-40ad-a089-77149c8592ac","metadata":{},"hash":"3rURA3NAjBbPHuOfsFmQc4zwl06mxpSGjEZOUnQ7JUU="},"PREVIOUS":{"nodeId":"8bbb0d25-5552-4777-b467-2500ab9dc014","metadata":{},"hash":"pwkzVOzbPYIxSKP/lKJ1Kz38HpONQaxwEp2qMK0zEGA="}},"hash":"8QmwwRwuOIAjwLC+V2jXjOc3NUVXNMgVPYXrGI8H7M4=","text":"For a cooking robot to operate effectively, it must:\n\n-   Adapt to Different Kitchen Environments: Recognize and adapt to the\n    varying layouts, storage solutions, and equipment found in different\n    kitchens. -   Understand Recipe Variations: Interpret a wide array of recipes,\n    accounting for the inevitable variability and occasional ambiguity\n    in cooking instructions. -   Learn from Human Behavior: By analyzing demonstrations, the robot\n    can accumulate knowledge about cooking techniques, ingredient\n    handling, and the sequence of steps involved in preparing various\n    dishes. The cooking assistant robot is a groundbreaking advancement in household\nrobotics, expanding the possibilities of robotic assistance in daily\nlife. However, the complexities of cooking tasks, combined with the need\nfor nuanced understanding and adaptability, present formidable\nchallenges. Overcoming these hurdles requires innovative approaches to\nrobot learning, sensory perception, and action execution, paving the way\nfor a future where robots not only assist in household chores but also\ntake on the role of culinary experts in our kitchens.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"e26e19b4-1db9-4937-8f18-82892249262b":{"id_":"e26e19b4-1db9-4937-8f18-82892249262b","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"c78ade8a-1928-4197-92d6-8422544801c0","metadata":{},"hash":"KZrTCJPOrP5GKP0kIUC33wnMrsn5K8LHy0ATX6bI1i8="},"NEXT":{"nodeId":"9462ce9e-0553-4e8d-a96f-4fe57dbdd15f","metadata":{},"hash":"xVGqNCeCgYVLoH3AEZfn+c5AMKeptxPRHYsgE+nsFfw="}},"hash":"BrX6/WU8jdwSX263w9Zt90wXJeqCO0rWVkRWmxOlp2w=","text":"### ... accomplish tasks together with humans \n\nDeveloping autonomous robots that collaborate effectively with humans in\nhousehold tasks represents one of the most intricate challenges in the\nfield of robotics. These robots are not just expected to execute tasks\nbut also to understand, adapt, and seamlessly integrate into human\nroutines and preferences. The ability to establish a shared\nunderstanding and coordinate actions with human partners is crucial,\nespecially in dynamic and unpredictable home environments. <figure id=\"fig:working-with-humans\">\n<img src=\"Ch01/18-joint-action.png\" />\n<figcaption>Robot agent preparing a meal together with a human. Here it\nis important to not only plan its own tasks but also coordinate with\nother agents like the human.</figcaption>\n</figure>\n\nFor successful collaboration, a robot must be equipped with a deep\nunderstanding of several nuanced human-centric concepts:\n\n-   Prioritization of Tasks (Importance): The robot must discern the\n    priority of tasks, such as understanding that removing boiling water\n    from a stove is more critical than setting the table at that\n    particular moment. -   Understanding Human Preferences (Cooperation): The robot should\n    recognize and respect human preferences, like acknowledging if a\n    human prefers to prepare the salad themselves while the robot sets\n    the table. -   Effective Communication: Ensuring clear and effective communication\n    channels, so the robot can understand instructions from humans and,\n    conversely, convey its intentions or needs clearly. -   Navigating Shared Spaces (Deference): The robot must be adept at\n    sharing space with humans, avoiding obstructing pathways, and being\n    able to pause or reroute its actions when in close proximity to\n    humans. In a collaborative setting, especially in tasks involving potential\nhazards like cooking, the robot's ability to ensure safety is paramount:\n\n-   Environmental Awareness: The robot should be constantly aware of its\n    surroundings, able to detect the presence of humans and other\n    obstacles to avoid collisions or unsafe interactions. -   Emergency Protocols: Implementing emergency stop mechanisms and\n    other safety protocols to immediately halt operations if a potential\n    risk is detected. -   Proactive Hazard Prevention: Understanding and anticipating\n    potential dangers, such as the risk of spilling boiling water, and\n    taking preemptive actions to prevent accidents.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"9462ce9e-0553-4e8d-a96f-4fe57dbdd15f":{"id_":"9462ce9e-0553-4e8d-a96f-4fe57dbdd15f","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"c78ade8a-1928-4197-92d6-8422544801c0","metadata":{},"hash":"KZrTCJPOrP5GKP0kIUC33wnMrsn5K8LHy0ATX6bI1i8="},"PREVIOUS":{"nodeId":"e26e19b4-1db9-4937-8f18-82892249262b","metadata":{},"hash":"BrX6/WU8jdwSX263w9Zt90wXJeqCO0rWVkRWmxOlp2w="}},"hash":"xVGqNCeCgYVLoH3AEZfn+c5AMKeptxPRHYsgE+nsFfw=","text":"Developing robots capable of such sophisticated human collaboration\ninvolves several key technical considerations:\n\n-   Advanced Sensory Systems: Equipping robots with sensors that can\n    detect and interpret human presence, gestures, and spoken commands\n    with high accuracy. -   Contextual Understanding and Adaptation: Enabling robots to\n    understand the context of tasks and adapt their actions based on the\n    dynamic preferences and behaviors of human partners. -   Real-Time Decision Making: Implementing algorithms that allow for\n    real-time analysis and decision-making, ensuring that the robot's\n    actions are always aligned with the current situation and human\n    partner's expectations. Robots designed for human collaboration in household tasks embody the\nconvergence of advanced robotics, artificial intelligence, and\nhuman-computer interaction disciplines. These robots hold the potential\nto not only assist in daily chores but also enrich human life by\nproviding companionship, understanding, and adaptability in shared\nliving environments. However, realizing this vision requires overcoming\nsubstantial challenges in robot design, sensory perception, context\nunderstanding, and safety assurance, paving the way for a future where\nhumans and robots collaborate seamlessly.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"e5a5eb08-f3e9-4286-9e02-bd7d53fde9a6":{"id_":"e5a5eb08-f3e9-4286-9e02-bd7d53fde9a6","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"b171181a-f3b3-4549-b0b2-10e9f4837be0","metadata":{},"hash":"14qNXm5+RCwsTUv77QIGC3UK14Z0c3RlPsvAYPdG1aw="}},"hash":"g8X10rJLFdisjgj0ZT1vpwWgrXFpu2hhAzsQobfEzOk=","text":"## Outline of the textbook","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"c5c3e57c-5e8b-4ce0-8879-15cf956cd1ef":{"id_":"c5c3e57c-5e8b-4ce0-8879-15cf956cd1ef","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"1f63a97b-9e35-4f95-a511-17ecd80904ba","metadata":{},"hash":"ZfA0wJLycFYlYcwY5N1jm9SskNVEQJs6bgM05xCJFls="},"NEXT":{"nodeId":"98a09ca4-7a33-4607-92b8-653b82a6984d","metadata":{},"hash":"YT9F+r3sY/Q/grvhA6vOTwow23JEBzmyxLDN3OxpgFs="}},"hash":"tHI7CIiXDBvKxUrPgCKjtiYuT+gyGj8Q1mrDFdQS24c=","text":"# Introduction \n\nRobots have become an indispensable part of our modern world,\ncontributing significantly to various industries and aspects of daily\nlife. Figure 1.1 shows several examples of different\nrobots accomplishing disparate tasks in diverse environments. Assembly\nand production robots are deployed in manufacturing and assembly lines\nmaking production processes more efficient and robust. Transportation\nrobots work in warehouses for material handling and logistics. They\nnavigate through warehouse environments, transporting goods and\noptimizing inventory management. Robotic vacuum cleaners have become\ncommon household appliances. They autonomously navigate living spaces,\nusing sensors to detect obstacles and efficiently clean floors. Drones\nare a form of flying robots, which are used for tasks like aerial\nphotography, surveillance, and delivery in various industries. Self-driving cars use a combination of sensors, cameras, and AI\nalgorithms to navigate roads, make decisions, and potentially\nrevolutionize the transportation industry. Inspection robots equipped\nwith cameras and sensors are employed for inspecting and maintaining\ninfrastructure, such as pipelines, bridges, and power lines, in\nchallenging or hazardous environments. Agricultural robots are\nincreasingly used for tasks like planting, harvesting, and monitoring\ncrops. They aim to improve efficiency and reduce the need for manual\nlabor.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"98a09ca4-7a33-4607-92b8-653b82a6984d":{"id_":"98a09ca4-7a33-4607-92b8-653b82a6984d","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"1f63a97b-9e35-4f95-a511-17ecd80904ba","metadata":{},"hash":"ZfA0wJLycFYlYcwY5N1jm9SskNVEQJs6bgM05xCJFls="},"PREVIOUS":{"nodeId":"c5c3e57c-5e8b-4ce0-8879-15cf956cd1ef","metadata":{},"hash":"tHI7CIiXDBvKxUrPgCKjtiYuT+gyGj8Q1mrDFdQS24c="},"NEXT":{"nodeId":"41793e6b-5988-459d-9cab-3dd777155923","metadata":{},"hash":"Q5cwYrYwDtbAerty8pqKceOsp0uS90zfeu6PDZwormM="}},"hash":"YT9F+r3sY/Q/grvhA6vOTwow23JEBzmyxLDN3OxpgFs=","text":"They aim to improve efficiency and reduce the need for manual\nlabor. <figure id=\"fig:robot-applications\">\n<table>\n<thead>\n<tr class=\"header\">\n<th style=\"text-align: center;\"><img\nsrc=\"img/01/DALLE/factory-robot.png\" style=\"width:45.0%\"\nalt=\"image\" /></th>\n<th style=\"text-align: center;\"><img src=\"img/01/DALLE/vaccum-robot.png\"\nstyle=\"width:45.0%\" alt=\"image\" /></th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td style=\"text-align: center;\"><img src=\"img/01/DALLE/drohne1.png\"\nstyle=\"width:45.0%\" alt=\"image\" /></td>\n<td style=\"text-align: center;\"><img\nsrc=\"img/01/DALLE/warehouse_bot.png\" style=\"width:45.0%\"\nalt=\"image\" /></td>\n</tr>\n</tbody>\n</table>\n<figcaption>The figure shows four different robots accomplishing four\ndifferent tasks in four different environments.</figcaption>\n</figure>\n\nThe practicality and success of these varied and impressive robotic\napplications is a result of the ingenuity, competence, and foresight of\nrobot engineers. These experts meticulously define tasks and engineer\nthe operational environments to preclude the necessity of executing\nopen, unconstrained tasks in uncontrolled settings. By minimizing the\ncomplexities and unpredictability inherent to these tasks and\nenvironments, they successfully circumvent a vast amount and possibly\nopen-ended number of individual challenges. This proactive approach\nobviates the need for overly intricate control programs, ensuring that\nthe robots perform efficiently and effectively within their designated\nparameters. One way to reduce complexity is to realize robot applications through\nsingle-purpose robots. Single-purpose robots are specifically designed\nfor the respective tasks to excel in a particular function, enhancing\ntheir efficiency and reliability within a defined scope. Consider, for\nexample, robotic vacuum cleaners or self-driving vehicles. Robotic\nvacuum cleaners are equipped with coverage algorithms. These algorithms\nenable the robot to systematically cover all reachable areas during\ncleaning, ensuring comprehensive coverage without redundancy. Autonomous\nvehicles are programmed for place-to-place navigation tasks. They use\nadvanced navigation algorithms and sensor systems to move from one\nlocation to another without colliding with obstacles or other entities. This careful planning minimizes the risk of accidents.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"41793e6b-5988-459d-9cab-3dd777155923":{"id_":"41793e6b-5988-459d-9cab-3dd777155923","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"1f63a97b-9e35-4f95-a511-17ecd80904ba","metadata":{},"hash":"ZfA0wJLycFYlYcwY5N1jm9SskNVEQJs6bgM05xCJFls="},"PREVIOUS":{"nodeId":"98a09ca4-7a33-4607-92b8-653b82a6984d","metadata":{},"hash":"YT9F+r3sY/Q/grvhA6vOTwow23JEBzmyxLDN3OxpgFs="}},"hash":"Q5cwYrYwDtbAerty8pqKceOsp0uS90zfeu6PDZwormM=","text":"This careful planning minimizes the risk of accidents. If the tasks themselves cannot be sufficiently simplified, robot\nengineers sometimes try to further reduce complexity by structuring the\nenvironment. Structuring the working environment is crucial for\nsupporting successful robot actions. This involves creating a controlled\nand optimized setting where robots can operate efficiently. Fixtures and\nmountings in an automobile factory, for instance, ensure that objects\nare positioned optimally for the robots to perform their tasks. In an\nautomobile factory, robots are programmed to execute very fast and\naccurate motions with high reliability and repeatability. This precision\nis essential in manufacturing processes to maintain product quality and\nproduction speed. <figure id=\"fig:grasping-a-pot\">\n<img src=\"Ch01/01-holding-pot.png\" />\n<figcaption>Modern mobile manipulation robot making\npopcorn.</figcaption>\n</figure>\n\nBesides specialized, single-purpose robots, the realm of robotics is\nexpanding to include general-purpose robots, such as the one illustrated\nin Figure 1.2, which are becoming increasingly\nprevalent. These versatile robots typically feature designs inspired by\nthe human form, providing arms and grippers for manipulation, and heads\nequipped with cameras that can be pointed into various directions. With\ntheir advanced motion and physical manipulation abilities, these robots\nare adept at performing a wide array of manipulation tasks. From setting\nand clearing the table to heating meals in the microwave, preparing\npopcorn, replenishing the coffee machine, and brewing coffee, their\ncapabilities extend to a myriad of daily activities. With the sensing and motion capabilities of these general purpose robots\nit is possible to accomplish a dynamically changing and expanding set of\nhuman-scale everyday manipulation activities in open human living\nenvironments -- if their control programs manage the complexity of the\nnecessary information processing tasks.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"}},"type":"simple_dict"}}}